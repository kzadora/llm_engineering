{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os, json, random, time, tempfile, subprocess\n",
    "from io import BytesIO\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5eaf3-ed4c-4fc3-a3bc-455a76cd6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API initialization\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc962987-7ba6-435b-bef2-68ee8f6da219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System message\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are a helpful assistant that can provide helpful suggestions on how to deal with problems in life.\n",
    "When someone asks for advice, ask clarifying questions about their situation \n",
    "to understand their problem deeply, including all people involved.\n",
    "When providing advice, try to stay positive. Do not put blame on anyone.\n",
    "Try to suggest a way for your interlocutor to assess the situation objectively \n",
    "and find a common ground with all people involved.\n",
    "You can build better connection with the person you are talking to by introducing yourself \n",
    "and giving them your name. Let them refer to you by your name.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2445306c-0783-4c5b-8ce1-b048d3d9f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI tool definitions and helper functions.\n",
    "\n",
    "random.seed()\n",
    "\n",
    "def get_assistant_name():\n",
    "    choices = [\"Alan\", \"Beth\", \"Charlie\", \"David\", \"Elanor\", \"Gerald\", \"Helen\"]\n",
    "    return random.choice(choices)\n",
    "\n",
    "get_assistant_name_tool = {\n",
    "    \"name\": \"get_assistant_name\",\n",
    "    \"description\": \"\"\"Gets the name of the assistant (you) for the purpose of introducing yourself \n",
    "       to the person you are talking to.\"\"\",\n",
    "    \"impl\": get_assistant_name\n",
    "}\n",
    "\n",
    "tools_impl = [{\"type\": \"function\", \"function\": get_assistant_name_tool}]\n",
    "# Remove \"impl\" from tools for the purpose of calling OpenAI (not serializable as JSON)\n",
    "tools = [\n",
    "    {**t, \"function\": {k: v for k, v in t[\"function\"].items() if k != \"impl\"} } for t in tools_impl\n",
    "]\n",
    "\n",
    "\n",
    "def call_tool(call):\n",
    "    known = list(filter(lambda t: t[\"function\"][\"name\"] == call.function.name, tools_impl))\n",
    "    if len(known) == 0:\n",
    "        raise ValueError(f\"Unknown tool call: {call.function.name}\")\n",
    "    tool = list(known)[0]\n",
    "    if tool[\"type\"] == \"function\":\n",
    "        args = json.loads(call.function.arguments)\n",
    "        return tool[\"function\"][\"impl\"](**args)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown tool type: {tool.type}\")\n",
    "\n",
    "\n",
    "def handle_tool_calls(message):\n",
    "    responses = []\n",
    "\n",
    "    for call in message.tool_calls:\n",
    "        try:\n",
    "            result = call_tool(call)\n",
    "            content = result if isinstance(result, str) else json.dumps(result)\n",
    "            responses.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": call.id,\n",
    "                \"content\": content\n",
    "            })\n",
    "        except Exception as e:\n",
    "            responses.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": call.id,\n",
    "                \"content\": json.dumps({\"error\": str(e)})\n",
    "            })\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b33795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text-to-speech function\n",
    "# Requires ffmpeg software to be installed on the system, see https://ffmpeg.org/ for details.\n",
    "\n",
    "def say(message):\n",
    "    if not message:\n",
    "        return\n",
    "\n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"shimmer\",\n",
    "        input=message,\n",
    "        instructions=\"Please read this text in a friendly, relaxed, unhurried, and conversational tone.\",\n",
    "        response_format=\"mp3\"\n",
    "    )\n",
    "    audio_stream = BytesIO(response.content)\n",
    "    \n",
    "    with tempfile.NamedTemporaryFile(delete=False, delete_on_close=False, suffix=\".mp3\", mode=\"wb\") as temp_file:\n",
    "        temp_file.write(audio_stream.read())\n",
    "        temp_file.flush()\n",
    "\n",
    "    try:\n",
    "        subprocess.run([\"ffplay\", \"-nodisp\", \"-autoexit\", \"-hide_banner\", temp_file.name])\n",
    "    finally:\n",
    "        os.remove(temp_file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268cddf3-c125-448c-afbe-62e2702b54ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat function, handling the single turn of the LLM conversation loop\n",
    "\n",
    "def chat(user_message, history, use_voice):\n",
    "    history = history + [{\"role\": \"user\", \"content\": user_message}]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        tool_message = response.choices[0].message\n",
    "        tool_responses = handle_tool_calls(tool_message)\n",
    "        messages.append(tool_message)\n",
    "        for tr in tool_responses:\n",
    "            messages.append(tr)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    \n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "    if use_voice:\n",
    "        say(reply)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c816aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Gradio UI\n",
    "\n",
    "ui_running = True\n",
    "\n",
    "with gr.Blocks() as appUI:\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            gr.Markdown(\"## OpenAI Chat with Voice Input and Output\\nPress End Chat button to stop the conversation.\")\n",
    "        with gr.Column(scale=1):\n",
    "            speech_enabled = gr.Checkbox(label=\"Make assistant speak\", value=False)\n",
    "        with gr.Column(scale=1):\n",
    "            end_chat = gr.Button(\"End chat\", variant=\"stop\")\n",
    "\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "\n",
    "    with gr.Row():\n",
    "        text_input = gr.Textbox(label=\"Type your question\")\n",
    "\n",
    "    with gr.Row():\n",
    "        audio_input = gr.Audio(\n",
    "            sources=[\"microphone\"], \n",
    "            type=\"filepath\", \n",
    "            label=\"Press Record to speak your question\"\n",
    "        )\n",
    "    \n",
    "    def on_text_input(user_message, history, use_voice):\n",
    "        return \"\", chat(user_message, history, use_voice)\n",
    "    \n",
    "    text_input.submit(\n",
    "        on_text_input, \n",
    "        inputs=[text_input, chatbot, speech_enabled], \n",
    "        outputs=[text_input, chatbot]\n",
    "    )\n",
    "\n",
    "    def on_audio_input(audio_file, history, use_voice):\n",
    "        if audio_file is None:\n",
    "            return None, history\n",
    "        with open(audio_file, \"rb\") as file:\n",
    "            transcription = openai.audio.transcriptions.create(\n",
    "                model=\"gpt-4o-mini-transcribe\",\n",
    "                file=file\n",
    "            )\n",
    "        return None, chat(transcription.text, history, use_voice)\n",
    "    \n",
    "    audio_input.change(\n",
    "        on_audio_input,\n",
    "        inputs=[audio_input, chatbot, speech_enabled],\n",
    "        outputs=[audio_input, chatbot]\n",
    "    )\n",
    "\n",
    "    def on_end_chat():\n",
    "        global ui_running\n",
    "        ui_running = False\n",
    "    \n",
    "    end_chat.click(fn=on_end_chat)\n",
    "\n",
    "appUI.launch()\n",
    "\n",
    "# The following is useful for debugging (keeps the cell running, so breakpoints in other cells will work)\n",
    "# To debug, open notebook in VS Code and use \"debug cell\" command. Comment out the code below if not needed.\n",
    "while ui_running:\n",
    "    time.sleep(1)\n",
    "appUI.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52207bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
